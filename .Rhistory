dflist <-c("<url>https://xcd32112.smart_meter.com</url>",
"<url>http://tXh67.dia_meter.com</url>",
"<url>http://yT5495.smart_meter.com</url>",
"<url>https://ret323_TRu.crown.com</url>",
"<url>https://luwr3243.celcius.com</url>")
library(tm)
dflist <-VectorSource(dflist)
dflist
class(dflist)
dfcorpus<-corpus(dflist)
dfcorpus<-vcorpus(dflist)
dfcorpus<-Vcorpus(dflist)
dfcorpus<-VCorpus(dflist)
dfcorpus[1]
View(dfcorpus)
View(dflist)
View(dfcorpus)
dflist <-c("<url>https://xcd32112.smart_meter.com</url>",
"<url>http://tXh67.dia_meter.com</url>",
"<url>http://yT5495.smart_meter.com</url>",
"<url>https://ret323_TRu.crown.com</url>",
"<url>https://luwr3243.celcius.com</url>")
library(tm)
dflist <-VectorSource(dflist)
dfcorpus<-VCorpus(dflist)
dfcorpus[1]
class(dflist)
View(dflist)
View(dfcorpus)
dfcorpus[3]
View(dfcorpus)
dfcorpus[["2"]][["content"]]
dflist[3]
my_string <- "Example STRING, with example numbers (12, 15 and also 10.2)?!"
grep("\\?",my_string_vector)
my_string_vector <- str_split(my_string, "!")[[1]]
my_string <- "Example STRING, with example numbers (12, 15 and also 10.2)?!"
lower_string <- tolower(my_string)
second_string <- "Wow, two sentences."
my_string <- paste(my_string,second_string,sep = " ")
my_string_vector <- str_split(my_string, "!")[[1]]
grep("\\?",my_string_vector)
second_string <- "Wow, two sentences."
my_string <- paste(my_string,second_string,sep = " ")
my_string_vector <- str_split(my_string, "!")[[1]]
install.packages("str_split")
install.packages("stringr", dependencies = TRUE)
library(stringr)
install.packages("stringr", dependencies = TRUE)
my_string <- "Example STRING, with example numbers (12, 15 and also 10.2)?!"
lower_string <- tolower(my_string)
second_string <- "Wow, two sentences."
my_string <- paste(my_string,second_string,sep = " ")
my_string_vector <- str_split(my_string, "!")[[1]]
grep("\\?",my_string_vector)
my_string_vector <-stringr:: str_split(my_string, "!")[[1]]
grep("\\?",my_string_vector)
grepl("\\?",my_string_vector[1])
text <- gsub("https?://.+", "", dflist)
text
text
dflist <-c("<url>https://xcd32112.smart_meter.com</url>",
"<url>http://tXh67.dia_meter.com</url>",
"<url>http://yT5495.smart_meter.com</url>",
"<url>https://ret323_TRu.crown.com</url>",
"<url>https://luwr3243.celcius.com</url>")
text <- gsub("https?://.+", "", dflist)
text
text <- gsub("https?://.-", "", dflist)
text
text <- gsub("https", "", dflist)
text
text <- gsub("https,http", "", dflist)
text
text <- gsub("https", "", dflist)
text
text <- gsub("<url>https://", "", dflist)
text
text <- gsub("<url>https://"|"<url>http://", "", dflist)
text <- gsub("<url>https://"||"<url>http://", "", dflist)
gsubfn(".", list("<url>https://" = "", "<url>http://"= ""), x)
install.packages("‘gsubfn’")
install.packages('gsubfn')
gsubfn(".", list("<url>https://" = "", "<url>http://"= ""), x)
library('gsubfn')
text <-gsubfn(".", list("<url>https://" = "", "<url>http://"= ""), x)
text <-gsubfn(".", list("<url>https://" = "", "<url>http://"= ""), dflist)
text
text <-gsubfn(".", list("https://" = "", "http://"= ""), dflist)
text
dflist <-c("<url>https://xcd32112.smart_meter.com</url>",
"<url>http://tXh67.dia_meter.com</url>",
"<url>http://yT5495.smart_meter.com</url>",
"<url>https://ret323_TRu.crown.com</url>",
"<url>https://luwr3243.celcius.com</url>")
text <-gsubfn(".", list("https://" = "", "http://"= ""), dflist)
text
toreplace<-list("https://" = "", "http://"= "")
text <-gsubfn(".",toreplace , dflist)
text
toreplace
toreplace<-list("https://" = "", "http://"= "")
text <-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist)
text
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
text <-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist)
text
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
link <-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist)
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
link <-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist)
link
dflist <-as.data.frame(read_csv("country_vaccination_stats.csv"))
zrequire('timeDate')
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls)
library(elasticnet)
library(broom)
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix)
library(kernlab)
library(e1071)
library(rpart)
library(pgmm)
library(dslabs)
library(rpart.plot)
library(partykit)
library(ipred)
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools)
library(FNN)
require(readxl)
require(ggplot2)
require(dplyr)
require(lubridate)
require(naniar)
require(caret)
require(lattice)
require(hexbin)
require(corrplot)
require(scales)
require(tidyverse)
library(Dict)
require(caTools)
require(gbm)
require(TTR)
library(reshape)
library(timeDate)
library(caret)
library(pspline)
library(plyr)
library(dplyr)
library(naniar)
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls)
library(elasticnet)
library(broom)
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix)
library(kernlab)
library(e1071)
library(rpart)
library(pgmm)
library(dslabs)
library(rpart.plot)
library(partykit)
library(ipred)
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools)
library(FNN)
dflist <-as.data.frame(read_csv("country_vaccination_stats.csv"))
View(dflist)
dflist <-as.data.frame(read_csv("link.csv"))
dflist <-as.data.frame(read_csv("links.csv"))
dflist <-as.data.frame(read_xlsx("links.csv"))
dflist <-as.data.frame(read_xlsx("links.xslx"))
dflist <-as.data.frame(read_xlsx("links.xlsx"))
dflist
dflist[,2]
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist[,2]
dflist <-as.data.frame(read_xlsx("links.xlsx"))
dflist
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist
dflist <-as.data.frame(read_xlsx("links.xlsx"))
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist
dflist <-as.data.frame(read_xlsx("links.xlsx"))
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist[,2]
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist[,2]
dflist <-as.data.frame(read_xlsx("links.xlsx"))
dflist
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist
dflist[,2]<-tolower(dflist[,2])
dflist
dfplot <-as.data.frame(read_xlsx("DailyActivities.xlsx"))
df1 = melt(dfplot, id.vars=c("Area of Interest"))
colnames(df1)=c("Area of Interest","Person","Hour")
str(df1)
p <- ggplot(df1, aes(x=`Area of Interest`, y=Hour)) +
geom_boxplot() + geom_point(aes(colour=Person))+ ylim(1,12)
zrequire('timeDate')
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls)
library(elasticnet)
library(broom)
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix)
library(kernlab)
library(e1071)
library(rpart)
library(pgmm)
library(dslabs)
library(rpart.plot)
library(partykit)
library(ipred)
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools)
library(FNN)
require(readxl)
require(ggplot2)
require(dplyr)
require(lubridate)
require(naniar)
require(caret)
require(lattice)
require(hexbin)
require(corrplot)
require(scales)
require(tidyverse)
library(Dict)
require(caTools)
require(gbm)
require(TTR)
library(reshape)
library(timeDate)
library(caret)
library(pspline)
library(plyr)
library(dplyr)
library(naniar)
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls)
library(elasticnet)
library(broom)
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix)
library(kernlab)
library(e1071)
library(rpart)
library(pgmm)
library(dslabs)
library(rpart.plot)
library(partykit)
library(ipred)
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools)
library(FNN)
####QUESTION 3
####
dfplot <-as.data.frame(read_xlsx("DailyActivities.xlsx"))
df1 = melt(dfplot, id.vars=c("Area of Interest"))
colnames(df1)=c("Area of Interest","Person","Hour")
str(df1)
p <- ggplot(df1, aes(x=`Area of Interest`, y=Hour)) +
geom_boxplot() + geom_point(aes(colour=Person))+ ylim(1,12)
View(p)
p
View(df1)
####
dfplot <-as.data.frame(read_xlsx("DailyActivities.xlsx"))
df1 = melt(dfplot, id.vars=c("Area of Interest"))
colnames(df1)=c("Area of Interest","Person","Hour")
str(df1)
p <- ggplot(df1, aes(x=`Area of Interest`, y=Hour)) +
geom_boxplot() + geom_point(aes(colour=Person))+ ylim(0,12)
p
df <-as.data.frame(read_csv("country_vaccination_stats.csv"))
cdf  <-as.data.frame(read_csv("country_vaccination_stats.csv"))
vis_miss(df)
str(df)
df$date <- as.Date(df$date, format =  "%m/%d/%Y")
df<- df %>% arrange(date)
df$dateindex <- c(1,1+cumsum(diff(df$date)!=0))
sil<- df %>%
group_by(country) %>%
slice(which.min(daily_vaccinations)) %>%
dplyr::select(country,daily_vaccinations)
colnames(sil)[2]<-"minvalue"
df <- left_join(df, sil, by = c("country"))
sil
sil<- df %>%
group_by(country) %>%
slice(which.min(daily_vaccinations)) %>%
dplyr::select(country,daily_vaccinations)
View(sil)
df <- left_join(df, sil, by = c("country"))
View(df)
df<-  df %>%mutate(daily_vaccinations = case_when(
!is.na(daily_vaccinations)~ daily_vaccinations,
is.na(daily_vaccinations) ~ minvalue))
zrequire('timeDate')
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls)
library(elasticnet)
library(broom)
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix)
library(kernlab)
library(e1071)
library(rpart)
library(pgmm)
library(dslabs)
library(rpart.plot)
library(partykit)
library(ipred)
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools)
library(FNN)
require(readxl)
require(ggplot2)
require(dplyr)
require(lubridate)
require(naniar)
require(caret)
require(lattice)
require(hexbin)
require(corrplot)
require(scales)
require(tidyverse)
library(Dict)
require(caTools)
require(gbm)
require(TTR)
library(reshape)
library(timeDate)
library(caret)
library(pspline)
library(plyr)
library(dplyr)
library(naniar)
library(caret)
library(tidyverse)
library(AppliedPredictiveModeling)
library(pls)
library(elasticnet)
library(broom)
library(glmnet)
library(MASS)
library(ISLR)
library(PerformanceAnalytics)
library(funModeling)
library(Matrix)
library(kernlab)
library(e1071)
library(rpart)
library(pgmm)
library(dslabs)
library(rpart.plot)
library(partykit)
library(ipred)
library(randomForest)
library(gbm)
library(nnet)
library(neuralnet)
library(GGally)
library(NeuralNetTools)
library(FNN)
###############   QUESTION 4
df <-as.data.frame(read_csv("country_vaccination_stats.csv"))
cdf  <-as.data.frame(read_csv("country_vaccination_stats.csv"))
# NA
vis_miss(df)
str(df)
df$date <- as.Date(df$date, format =  "%m/%d/%Y")
df<- df %>% arrange(date)
df$dateindex <- c(1,1+cumsum(diff(df$date)!=0))
### create a datafrime which contains min values
#for each country (sil)
sil<- df %>%
group_by(country) %>%
slice(which.min(daily_vaccinations)) %>%
dplyr::select(country,daily_vaccinations)
colnames(sil)[2]<-"minvalue"
df <- left_join(df, sil, by = c("country"))
##assign 0 to na in minvalue column(no values as like kuwait )
df[is.na(df$minvalue),]$minvalue<-0
## final result
df<-  df %>%mutate(daily_vaccinations = case_when(
!is.na(daily_vaccinations)~ daily_vaccinations,
is.na(daily_vaccinations) ~ minvalue))
df
df<-df %>% arrange(country, date)
df<-df %>%dplyr::group_by(country) %>% dplyr::mutate(median=median(daily_vaccinations))
dfmax <- as.data.frame(df %>%
group_by(country) %>%
slice(which.max(median)) %>%
dplyr::select(country,median))
dfmax %>% slice_max(median, n = 3)
library(Rcpp)
sqltbl <-as.data.frame(read_csv("country_vaccination_stats.csv"))
sqltbl$date <- as.Date(sqltbl$date, format =  "%m/%d/%Y")
sqltbl<- sqltbl %>% arrange(date)
tblsql_median<- sqldf(
"SELECT country,MEDIAN(daily_vaccinations) as median
FROM sqltbl
GROUP BY country")
install.packages('Rcpp')
library(Rcpp)
install.packages("Rcpp")
library(sqldf)
library(Rcpp)
library(sqldf)
sqltbl <-as.data.frame(read_csv("country_vaccination_stats.csv"))
sqltbl
sqltbl$date <- as.Date(sqltbl$date, format =  "%m/%d/%Y")
sqltbl<- sqltbl %>% arrange(date)
tblsql_median<- sqldf(
"SELECT country,MEDIAN(daily_vaccinations) as median
FROM sqltbl
GROUP BY country")
tblsql_median
tblsql_join<-  sqldf(
"SELECT a.country as country ,a.date as date ,a.daily_vaccinations as daily_vaccinations,
b.median as median from sqltbl as a  left join tblsql_median as b on a.country=b.country
")
tblsql_join
dflist
install.packages('gsubfn')
library('gsubfn')
#### I created excel file which demonstrates html tags
dflist <-as.data.frame(read_xlsx("links.xlsx"))
##Xml tags and protocol parts is guaranteed to be lower case
####Access link part that we are interested in can have alpha-numeric, case insensitive characters,
#underscore ( _ ) character and dot ( . ) character only.
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist[,2]<-tolower(dflist[,2])
install.packages("gsubfn")
library('gsubfn')
#### I created excel file which demonstrates html tags
dflist <-as.data.frame(read_xlsx("links.xlsx"))
##Xml tags and protocol parts is guaranteed to be lower case
####Access link part that we are interested in can have alpha-numeric, case insensitive characters,
#underscore ( _ ) character and dot ( . ) character only.
toreplace<-list("https://" = "", "http://"= "","<url>"="","</url>"="")
dflist[,2]<-gsubfn(paste(names(toreplace),collapse="|"),toreplace,dflist[,2])
dflist[,2]<-tolower(dflist[,2])
#Answer
dflist
print(dflist)
